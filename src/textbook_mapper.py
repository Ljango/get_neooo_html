#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•™ææ˜ å°„ç”Ÿæˆå™¨
å°†æ•™æç›®å½•(ç« /èŠ‚/å°èŠ‚)æ˜ å°„åˆ°è¯¾æ ‡çŸ¥è¯†ç‚¹(KeyPoint)
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
DATA_ROOT = PROJECT_ROOT / "å›¾è°±æ•°æ®"
TEXTBOOK_ROOT = PROJECT_ROOT / "æ•™æç›®å½•"


class TextbookMapper:
    """æ•™ææ˜ å°„ç”Ÿæˆå™¨"""
    
    def __init__(self, subject: str, textbook_path: str, book_id: str):
        """
        åˆå§‹åŒ–
        
        Args:
            subject: å­¦ç§‘è·¯å¾„ï¼Œå¦‚ "é«˜ä¸­æ•°å­¦"
            textbook_path: æ•™æJSONè·¯å¾„ï¼Œç›¸å¯¹äº TEXTBOOK_ROOT
            book_id: æ•™æIDï¼Œç”¨äºç”Ÿæˆå®ä½“æ ‡è¯†ç¬¦ï¼Œå¦‚ "renjiao_B"
        """
        self.subject = subject
        self.textbook_path = TEXTBOOK_ROOT / textbook_path
        self.book_id = book_id
        self.output_dir = DATA_ROOT / subject / "books" / book_id
        
        # åŠ è½½çŸ¥è¯†ç‚¹æ•°æ®
        self.keypoints: Dict[str, dict] = {}
        self._load_keypoints()
        
        # æ•™ææ•°æ®
        self.textbook_data: dict = {}
        
        # ç”Ÿæˆçš„å®ä½“å’Œå…³ç³»
        self.entities: List[dict] = []
        self.relations: List[dict] = []
        
    def _load_keypoints(self):
        """åŠ è½½è¯¾æ ‡çŸ¥è¯†ç‚¹"""
        kp_path = DATA_ROOT / self.subject / "entities" / "KeyPoint.json"
        if kp_path.exists():
            with open(kp_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            for kp in data.get("entities", []):
                self.keypoints[kp["identifier"]] = kp
            print(f"ğŸ“š åŠ è½½ {len(self.keypoints)} ä¸ªçŸ¥è¯†ç‚¹")
    
    def load_textbook(self) -> 'TextbookMapper':
        """åŠ è½½æ•™ææ•°æ®"""
        if not self.textbook_path.exists():
            raise FileNotFoundError(f"æ•™ææ–‡ä»¶ä¸å­˜åœ¨: {self.textbook_path}")
        
        with open(self.textbook_path, 'r', encoding='utf-8') as f:
            self.textbook_data = json.load(f)
        
        print(f"ğŸ“– åŠ è½½æ•™æ: {self.textbook_data.get('title', 'Unknown')}")
        return self
    
    def generate_mapping(self, mapping_rules: Optional[Dict[str, List[str]]] = None) -> 'TextbookMapper':
        """
        ç”Ÿæˆç« èŠ‚åˆ°çŸ¥è¯†ç‚¹çš„æ˜ å°„
        
        Args:
            mapping_rules: æ‰‹åŠ¨æ˜ å°„è§„åˆ™ï¼Œæ ¼å¼ä¸º {"ç« èŠ‚æ ‡é¢˜": ["kp_id1", "kp_id2"]}
                          å¦‚æœä¸æä¾›ï¼Œåˆ™ä½¿ç”¨è‡ªåŠ¨åŒ¹é…
        """
        if not self.textbook_data:
            raise ValueError("è¯·å…ˆè°ƒç”¨ load_textbook() åŠ è½½æ•™æ")
        
        book_title = self.textbook_data.get("title", "æœªçŸ¥æ•™æ")
        chapters = self.textbook_data.get("chapters", [])
        
        print(f"ğŸ”„ ç”Ÿæˆæ˜ å°„: {len(chapters)} ç« ")
        
        # ç« èŠ‚è®¡æ•°å™¨
        chapter_count = 0
        section_count = 0
        subsection_count = 0
        
        for chapter in chapters:
            chapter_count += 1
            chapter_id = f"urn:jy:textbook:{self.book_id}:chapter:ch{chapter_count:03d}"
            chapter_title = chapter.get("title", f"ç¬¬{chapter_count}ç« ")
            
            # åˆ›å»ºç« å®ä½“
            self.entities.append({
                "identifier": chapter_id,
                "title": chapter_title,
                "type": "Chapter",
                "book": book_title,
                "bookId": self.book_id,
                "level": 1,
                "index": chapter.get("index", chapter_count)
            })
            
            # åŒ¹é…çŸ¥è¯†ç‚¹
            matched_kps = self._match_keypoints(chapter_title, mapping_rules)
            for kp_id in matched_kps:
                self.relations.append({
                    "source": chapter_id,
                    "target": kp_id,
                    "relationName": "chapterMatchesKeyPointPrimary",
                    "label": "ç« èŠ‚åŒ¹é…çŸ¥è¯†ç‚¹"
                })
            
            # å¤„ç†èŠ‚
            section_idx = 0
            for child in chapter.get("children", []):
                if child.get("level") == 2:
                    section_idx += 1
                    section_count += 1
                    section_id = f"urn:jy:textbook:{self.book_id}:section:sec{section_count:03d}"
                    section_title = child.get("title", f"ç¬¬{section_idx}èŠ‚")
                    
                    # åˆ›å»ºèŠ‚å®ä½“
                    self.entities.append({
                        "identifier": section_id,
                        "title": section_title,
                        "type": "Section",
                        "book": book_title,
                        "bookId": self.book_id,
                        "level": 2,
                        "index": child.get("index", section_idx),
                        "parentChapter": chapter_id
                    })
                    
                    # ç« åŒ…å«èŠ‚
                    self.relations.append({
                        "source": chapter_id,
                        "target": section_id,
                        "relationName": "chapterContainsSection",
                        "label": "åŒ…å«"
                    })
                    
                    # åŒ¹é…çŸ¥è¯†ç‚¹
                    matched_kps = self._match_keypoints(section_title, mapping_rules)
                    for kp_id in matched_kps:
                        self.relations.append({
                            "source": section_id,
                            "target": kp_id,
                            "relationName": "sectionMatchesKeyPointPrimary",
                            "label": "èŠ‚åŒ¹é…çŸ¥è¯†ç‚¹"
                        })
                    
                    # å¤„ç†å°èŠ‚
                    subsection_idx = 0
                    for subchild in child.get("children", []):
                        if subchild.get("level") == 3:
                            subsection_idx += 1
                            subsection_count += 1
                            subsection_id = f"urn:jy:textbook:{self.book_id}:subsection:ssec{subsection_count:03d}"
                            subsection_title = subchild.get("title", f"ç¬¬{subsection_idx}å°èŠ‚")
                            
                            # åˆ›å»ºå°èŠ‚å®ä½“
                            self.entities.append({
                                "identifier": subsection_id,
                                "title": subsection_title,
                                "type": "SubSection",
                                "book": book_title,
                                "bookId": self.book_id,
                                "level": 3,
                                "index": subchild.get("index", subsection_idx),
                                "parentSection": section_id
                            })
                            
                            # èŠ‚åŒ…å«å°èŠ‚
                            self.relations.append({
                                "source": section_id,
                                "target": subsection_id,
                                "relationName": "sectionContainsSubSection",
                                "label": "åŒ…å«"
                            })
                            
                            # åŒ¹é…çŸ¥è¯†ç‚¹
                            matched_kps = self._match_keypoints(subsection_title, mapping_rules)
                            for kp_id in matched_kps:
                                self.relations.append({
                                    "source": subsection_id,
                                    "target": kp_id,
                                    "relationName": "subSectionMatchesKeyPointPrimary",
                                    "label": "å°èŠ‚åŒ¹é…çŸ¥è¯†ç‚¹"
                                })
        
        print(f"   âœ“ ç”Ÿæˆ {chapter_count} ç« , {section_count} èŠ‚, {subsection_count} å°èŠ‚")
        print(f"   âœ“ å…± {len(self.entities)} ä¸ªå®ä½“, {len(self.relations)} æ¡å…³ç³»")
        
        return self
    
    def _match_keypoints(self, title: str, mapping_rules: Optional[Dict[str, List[str]]]) -> List[str]:
        """
        åŒ¹é…ç« èŠ‚æ ‡é¢˜åˆ°çŸ¥è¯†ç‚¹
        
        Args:
            title: ç« èŠ‚æ ‡é¢˜
            mapping_rules: æ‰‹åŠ¨æ˜ å°„è§„åˆ™
            
        Returns:
            åŒ¹é…çš„çŸ¥è¯†ç‚¹IDåˆ—è¡¨
        """
        # ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨æ˜ å°„
        if mapping_rules and title in mapping_rules:
            return [f"urn:jy:math:SB0201:OB06:KeyPoint:{kp_id}" 
                    if not kp_id.startswith("urn:") else kp_id 
                    for kp_id in mapping_rules[title]]
        
        # è‡ªåŠ¨åŒ¹é…ï¼šåŸºäºå…³é”®è¯
        matched = []
        title_clean = self._clean_title(title)
        
        for kp_id, kp in self.keypoints.items():
            kp_title = kp.get("title", "")
            kp_clean = self._clean_title(kp_title)
            
            # å®Œå…¨åŒ¹é…æˆ–åŒ…å«åŒ¹é…
            if kp_clean and (kp_clean in title_clean or title_clean in kp_clean):
                matched.append(kp_id)
            # å…³é”®è¯åŒ¹é…
            elif self._keyword_match(title_clean, kp_clean):
                matched.append(kp_id)
        
        return matched[:3]  # æœ€å¤šè¿”å›3ä¸ªåŒ¹é…
    
    def _clean_title(self, title: str) -> str:
        """æ¸…ç†æ ‡é¢˜ï¼Œå»é™¤ç« èŠ‚ç¼–å·ç­‰"""
        # å»é™¤ç« èŠ‚ç¼–å·
        cleaned = re.sub(r'^[\d.]+\s*', '', title)
        cleaned = re.sub(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ç« èŠ‚è¯¾]\s*', '', cleaned)
        cleaned = re.sub(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]\s*', '', cleaned)
        return cleaned.strip()
    
    def _keyword_match(self, title: str, kp_title: str) -> bool:
        """å…³é”®è¯åŒ¹é…"""
        # å®šä¹‰å…³é”®è¯æ˜ å°„
        keywords_map = {
            "é›†åˆ": ["é›†åˆ"],
            "å‡½æ•°": ["å‡½æ•°"],
            "ä¸ç­‰å¼": ["ä¸ç­‰å¼"],
            "ç­‰å¼": ["ç­‰å¼"],
            "å‘½é¢˜": ["å‘½é¢˜", "é€»è¾‘"],
            "é‡è¯": ["é‡è¯"],
            "å……åˆ†": ["å……åˆ†æ¡ä»¶", "å¿…è¦æ¡ä»¶"],
            "å¿…è¦": ["å……åˆ†æ¡ä»¶", "å¿…è¦æ¡ä»¶"],
            "å•è°ƒ": ["å•è°ƒæ€§"],
            "å¥‡å¶": ["å¥‡å¶æ€§"],
            "ä¸€å…ƒäºŒæ¬¡": ["ä¸€å…ƒäºŒæ¬¡"],
            "å‡å€¼": ["å‡å€¼ä¸ç­‰å¼", "åŸºæœ¬ä¸ç­‰å¼"],
        }
        
        for keyword, matches in keywords_map.items():
            if keyword in title:
                for match in matches:
                    if match in kp_title:
                        return True
        return False
    
    def save(self) -> Tuple[str, str]:
        """
        ä¿å­˜ç”Ÿæˆçš„æ•°æ®
        
        Returns:
            (entities_path, relations_path)
        """
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        entities_path = self.output_dir / "entities.json"
        relations_path = self.output_dir / "relations.json"
        
        with open(entities_path, 'w', encoding='utf-8') as f:
            json.dump({"entities": self.entities}, f, ensure_ascii=False, indent=2)
        
        with open(relations_path, 'w', encoding='utf-8') as f:
            json.dump(self.relations, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²ä¿å­˜åˆ° {self.output_dir}")
        return str(entities_path), str(relations_path)


def generate_renjiao_b():
    """ç”Ÿæˆäººæ•™Bç‰ˆå¿…ä¿®ç¬¬ä¸€å†Œçš„æ˜ å°„"""
    
    # æ‰‹åŠ¨å®šä¹‰æ˜ å°„è§„åˆ™ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
    mapping_rules = {
        # ç¬¬ä¸€ç«  é›†åˆä¸å¸¸ç”¨é€»è¾‘ç”¨è¯­
        "ç¬¬ä¸€ç«  é›†åˆä¸å¸¸ç”¨é€»è¾‘ç”¨è¯­": ["kp00001", "kp00004", "kp00005"],
        "1.1 é›†åˆ": ["kp00001"],
        "1.1.1 é›†åˆåŠå…¶è¡¨ç¤ºæ–¹æ³•": ["kp00001"],
        "1.1.2 é›†åˆçš„åŸºæœ¬å…³ç³»": ["kp00002"],
        "1.1.3 é›†åˆçš„åŸºæœ¬è¿ç®—": ["kp00003"],
        "1.2 å¸¸ç”¨é€»è¾‘ç”¨è¯­": ["kp00004", "kp00005", "kp00006"],
        "1.2.1 å‘½é¢˜ä¸é‡è¯": ["kp00005"],
        "1.2.2 å…¨ç§°é‡è¯å‘½é¢˜ä¸å­˜åœ¨é‡è¯å‘½é¢˜çš„å¦å®š": ["kp00006"],
        "1.2.3 å……åˆ†æ¡ä»¶ã€å¿…è¦æ¡ä»¶": ["kp00004"],
        
        # ç¬¬äºŒç«  ç­‰å¼ä¸ä¸ç­‰å¼
        "ç¬¬äºŒç«  ç­‰å¼ä¸ä¸ç­‰å¼": ["kp00007", "kp00008", "kp00009", "kp00010"],
        "2.1 ç­‰å¼": ["kp00007", "kp00009"],
        "2.1.1 ç­‰å¼çš„æ€§è´¨ä¸æ–¹ç¨‹çš„è§£é›†": ["kp00007"],
        "2.1.2 ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹çš„è§£é›†åŠå…¶æ ¹ä¸ç³»æ•°çš„å…³ç³»": ["kp00009"],
        "2.1.3 æ–¹ç¨‹ç»„çš„è§£é›†": ["kp00007"],
        "2.2 ä¸ç­‰å¼": ["kp00007", "kp00008", "kp00010"],
        "2.2.1 ä¸ç­‰å¼åŠå…¶æ€§è´¨": ["kp00007"],
        "2.2.2 ä¸ç­‰å¼çš„è§£é›†": ["kp00007"],
        "2.2.3 ä¸€å…ƒäºŒæ¬¡ä¸ç­‰å¼çš„è§£æ³•": ["kp00010"],
        "2.2.4 å‡å€¼ä¸ç­‰å¼åŠå…¶åº”ç”¨": ["kp00008"],
        
        # ç¬¬ä¸‰ç«  å‡½æ•°
        "ç¬¬ä¸‰ç«  å‡½æ•°": ["kp00011", "kp00012", "kp00022", "kp00023"],
        "3.1 å‡½æ•°çš„æ¦‚å¿µä¸æ€§è´¨": ["kp00011", "kp00012"],
        "3.1.1 å‡½æ•°åŠå…¶è¡¨ç¤ºæ–¹æ³•": ["kp00011"],
        "3.1.2 å‡½æ•°çš„å•è°ƒæ€§": ["kp00012"],
        "3.1.3 å‡½æ•°çš„å¥‡å¶æ€§": ["kp00012"],
        "3.2 å‡½æ•°ä¸æ–¹ç¨‹ã€ä¸ç­‰å¼ä¹‹é—´çš„å…³ç³»": ["kp00022"],
        "3.3 å‡½æ•°çš„åº”ç”¨(ä¸€)": ["kp00023"],
        "3.4 æ•°å­¦å»ºæ¨¡æ´»åŠ¨:å†³å®šè‹¹æœçš„æœ€ä½³å‡ºå”®æ—¶é—´ç‚¹": ["kp00040"],
    }
    
    mapper = TextbookMapper(
        subject="é«˜ä¸­æ•°å­¦",
        textbook_path="æ•°å­¦/é«˜ä¸­/äººæ•™ç‰ˆï¼ˆBç‰ˆï¼‰ï¼ˆä¸»ç¼–ï¼šé«˜å­˜æ˜ï¼‰/å¿…ä¿® ç¬¬ä¸€å†Œ.json",
        book_id="renjiao_B"
    )
    
    mapper.load_textbook()
    mapper.generate_mapping(mapping_rules)
    mapper.save()
    
    return mapper


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ç”Ÿæˆäººæ•™Bç‰ˆå¿…ä¿®ç¬¬ä¸€å†Œæ•™ææ˜ å°„")
    print("="*60)
    
    generate_renjiao_b()


if __name__ == "__main__":
    main()
