#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONæ•°æ®å¯¼å‡ºä¸ºExcelå·¥å…·
ç”¨äºå­¦ç§‘è€å¸ˆå®¡æ ¸å›¾è°±æ•°æ®çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§

åŠŸèƒ½ï¼š
1. å¯¼å‡ºå®ä½“æ•°æ®ï¼šæ¯ç§å®ä½“ç±»å‹ä¸€ä¸ªsheetï¼ŒåŒ…å«å®ä½“å±æ€§å’ŒcontentJsonå±•å¼€å­—æ®µ
2. å¯¼å‡ºå…³ç³»æ•°æ®ï¼šåŒ…å«å¤´å°¾èŠ‚ç‚¹çš„åç§°ã€ç±»å‹ã€IDå’Œå…³ç³»åç§°
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
import pandas as pd
from collections import defaultdict


class Json2CsvExporter:
    """JSONæ•°æ®å¯¼å‡ºä¸ºExcelå·¥å…·"""
    
    def __init__(self, data_dir: str, output_dir: str = None):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼ˆåŒ…å«entitieså’Œrelationså­ç›®å½•ï¼‰
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºdata_diråŒçº§ç›®å½•
        """
        self.data_dir = Path(data_dir)
        self.entities_dir = self.data_dir / "entities"
        self.relations_dir = self.data_dir / "relations"
        
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = self.data_dir.parent / "å¯¼å‡ºæ•°æ®"
        
        self.output_dir.mkdir(exist_ok=True)
        
        # å®ä½“æ˜ å°„ï¼šidentifier -> {title, type, ...}
        self.entity_map: Dict[str, Dict[str, Any]] = {}
        
        # å­¦ç§‘åç§°ï¼ˆä»ç›®å½•åæå–ï¼‰
        self.subject_name = self.data_dir.name
        
        # ä¸ºæ¯ä¸ªå­¦ç§‘åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºæ–‡ä»¶å¤¹
        self.output_dir = self.output_dir / self.subject_name
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def load_entities(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        åŠ è½½æ‰€æœ‰å®ä½“æ•°æ®
        
        Returns:
            æŒ‰å®ä½“ç±»å‹åˆ†ç»„çš„å®ä½“å­—å…¸
        """
        entities_by_type = defaultdict(list)
        
        if not self.entities_dir.exists():
            print(f"âš ï¸  è­¦å‘Š: å®ä½“ç›®å½•ä¸å­˜åœ¨: {self.entities_dir}")
            return entities_by_type
        
        entity_files = list(self.entities_dir.glob('*.json'))
        print(f"\nğŸ“‚ æ‰¾åˆ° {len(entity_files)} ä¸ªå®ä½“æ–‡ä»¶")
        
        for entity_file in entity_files:
            try:
                with open(entity_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # å¤„ç†ä¸åŒçš„JSONæ ¼å¼
                if isinstance(data, dict) and 'entities' in data:
                    entity_list = data['entities']
                elif isinstance(data, list):
                    entity_list = data
                else:
                    print(f"  âš ï¸  è­¦å‘Š: {entity_file.name} æ ¼å¼ä¸æ”¯æŒ")
                    continue
                
                if not entity_list:
                    continue
                
                # è·å–å®ä½“ç±»å‹
                entity_type = entity_list[0].get('type', entity_file.stem)
                
                for entity in entity_list:
                    identifier = entity.get('identifier', '')
                    if identifier:
                        # å»ºç«‹æ˜ å°„
                        self.entity_map[identifier] = {
                            'title': entity.get('title', ''),
                            'type': entity.get('type', entity_type),
                            'description': entity.get('description', ''),
                            'entity': entity
                        }
                    
                    entities_by_type[entity_type].append(entity)
                
                print(f"  âœ“ {entity_file.name}: {len(entity_list)} ä¸ª {entity_type}")
            
            except Exception as e:
                print(f"  âœ— è¯»å– {entity_file.name} å¤±è´¥: {e}")
        
        total = sum(len(v) for v in entities_by_type.values())
        print(f"\nğŸ“Š æ€»è®¡åŠ è½½ {total} ä¸ªå®ä½“ï¼Œ{len(self.entity_map)} ä¸ªidentifieræ˜ å°„")
        return entities_by_type
    
    def clean_cell_value(self, value: Any) -> Any:
        """
        æ¸…ç†å•å…ƒæ ¼å€¼ï¼Œç§»é™¤Excelä¸æ”¯æŒçš„æ§åˆ¶å­—ç¬¦
        
        Args:
            value: åŸå§‹å€¼
            
        Returns:
            æ¸…ç†åçš„å€¼
        """
        if value is None:
            return ''
        
        if isinstance(value, str):
            # ç§»é™¤æ§åˆ¶å­—ç¬¦ï¼ˆä¿ç•™æ¢è¡Œç¬¦ã€åˆ¶è¡¨ç¬¦ï¼‰
            # Excelä¸æ”¯æŒçš„æ§åˆ¶å­—ç¬¦ï¼š\x00-\x08, \x0B-\x0C, \x0E-\x1F
            value = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F]', '', value)
            return value
        
        return value
    
    def expand_content_json(self, content_json: Any) -> Dict[str, Any]:
        """
        å±•å¼€contentJsonå­—æ®µä¸ºCJ_xxxæ ¼å¼
        
        Args:
            content_json: contentJsonå­—æ®µçš„å€¼
            
        Returns:
            å±•å¼€åçš„å­—æ®µå­—å…¸
        """
        if not content_json:
            return {}
        
        if isinstance(content_json, dict):
            result = {}
            for key, value in content_json.items():
                if isinstance(value, (list, dict)):
                    # å¤æ‚ç±»å‹è½¬ä¸ºJSONå­—ç¬¦ä¸²
                    json_str = json.dumps(value, ensure_ascii=False)
                    result[f'CJ_{key}'] = self.clean_cell_value(json_str)
                else:
                    result[f'CJ_{key}'] = self.clean_cell_value(value)
            return result
        else:
            json_str = json.dumps(content_json, ensure_ascii=False)
            return {'CJ_content': self.clean_cell_value(json_str)}
    
    def export_entities(self, entities_by_type: Dict[str, List[Dict[str, Any]]]):
        """
        å¯¼å‡ºå®ä½“æ•°æ®åˆ°Excel
        
        Args:
            entities_by_type: æŒ‰ç±»å‹åˆ†ç»„çš„å®ä½“å­—å…¸
        """
        output_file = self.output_dir / f"{self.subject_name}_å®ä½“æ•°æ®.xlsx"
        
        print(f"\nğŸ“ å¯¼å‡ºå®ä½“æ•°æ®åˆ°: {output_file}")
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            for entity_type, entities in sorted(entities_by_type.items()):
                print(f"  å¤„ç† {entity_type}: {len(entities)} ä¸ªå®ä½“")
                
                rows = []
                for entity in entities:
                    # åŸºç¡€å­—æ®µ
                    row = {
                        'å®ä½“ç±»å‹': self.clean_cell_value(entity.get('type', entity_type)),
                        'å®ä½“åç§°': self.clean_cell_value(entity.get('title', '')),
                        'å®ä½“ID': self.clean_cell_value(entity.get('identifier', '')),
                        'å®ä½“æè¿°': self.clean_cell_value(entity.get('description', '')),
                    }
                    
                    # å±•å¼€contentJson
                    content_json = entity.get('contentJson', {})
                    expanded = self.expand_content_json(content_json)
                    row.update(expanded)
                    
                    # æ·»åŠ å…¶ä»–å­—æ®µï¼ˆé™¤äº†å·²å¤„ç†çš„ï¼‰
                    for key, value in entity.items():
                        if key not in ['type', 'title', 'identifier', 'description', 'contentJson']:
                            if isinstance(value, (list, dict)):
                                json_str = json.dumps(value, ensure_ascii=False)
                                row[key] = self.clean_cell_value(json_str)
                            else:
                                row[key] = self.clean_cell_value(value)
                    
                    rows.append(row)
                
                # åˆ›å»ºDataFrame
                df = pd.DataFrame(rows)
                
                # ç¡®ä¿åˆ—é¡ºåºï¼šåŸºç¡€å­—æ®µåœ¨å‰ï¼ŒCJ_å­—æ®µåœ¨åï¼Œå…¶ä»–å­—æ®µæœ€å
                base_cols = ['å®ä½“ç±»å‹', 'å®ä½“åç§°', 'å®ä½“ID', 'å®ä½“æè¿°']
                cj_cols = [c for c in df.columns if c.startswith('CJ_')]
                other_cols = [c for c in df.columns if c not in base_cols and not c.startswith('CJ_')]
                
                df = df[base_cols + sorted(cj_cols) + other_cols]
                
                # å†™å…¥sheetï¼ˆsheetåç§°é™åˆ¶31å­—ç¬¦ï¼‰
                sheet_name = entity_type[:31] if len(entity_type) <= 31 else entity_type[:28] + '...'
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        print(f"âœ… å®ä½“æ•°æ®å¯¼å‡ºå®Œæˆ: {output_file}")
    
    def load_relations(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        åŠ è½½æ‰€æœ‰å…³ç³»æ•°æ®ï¼ŒæŒ‰æ–‡ä»¶åˆ†ç»„
        
        Returns:
            æŒ‰æ–‡ä»¶ååˆ†ç»„çš„å…³ç³»å­—å…¸ {æ–‡ä»¶å: [å…³ç³»åˆ—è¡¨]}
        """
        relations_by_file = {}
        
        if not self.relations_dir.exists():
            print(f"âš ï¸  è­¦å‘Š: å…³ç³»ç›®å½•ä¸å­˜åœ¨: {self.relations_dir}")
            return relations_by_file
        
        relation_files = list(self.relations_dir.glob('*.json'))
        print(f"\nğŸ“‚ æ‰¾åˆ° {len(relation_files)} ä¸ªå…³ç³»æ–‡ä»¶")
        
        total_relations = 0
        
        for relation_file in relation_files:
            try:
                with open(relation_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # å¤„ç†ä¸åŒçš„JSONæ ¼å¼
                if isinstance(data, dict):
                    if 'relations' in data:
                        relation_list = data['relations']
                    elif 'relationships' in data:
                        relation_list = data['relationships']
                    elif 'relation' in data:
                        relation_list = data['relation']
                    else:
                        print(f"  âš ï¸  è­¦å‘Š: {relation_file.name} æ ¼å¼ä¸æ”¯æŒ")
                        continue
                elif isinstance(data, list):
                    relation_list = data
                else:
                    print(f"  âš ï¸  è­¦å‘Š: {relation_file.name} æ ¼å¼ä¸æ”¯æŒ")
                    continue
                
                # ä½¿ç”¨æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºkey
                file_key = relation_file.stem
                relations_by_file[file_key] = relation_list
                total_relations += len(relation_list)
                print(f"  âœ“ {relation_file.name}: {len(relation_list)} ä¸ªå…³ç³»")
            
            except Exception as e:
                print(f"  âœ— è¯»å– {relation_file.name} å¤±è´¥: {e}")
        
        print(f"\nğŸ“Š æ€»è®¡åŠ è½½ {total_relations} ä¸ªå…³ç³»ï¼Œåˆ†å¸ƒåœ¨ {len(relations_by_file)} ä¸ªæ–‡ä»¶ä¸­")
        return relations_by_file
    
    def get_entity_info(self, identifier: str) -> Dict[str, str]:
        """
        æ ¹æ®identifierè·å–å®ä½“ä¿¡æ¯
        
        Args:
            identifier: å®ä½“identifier
            
        Returns:
            åŒ…å«titleå’Œtypeçš„å­—å…¸
        """
        if identifier in self.entity_map:
            entity_info = self.entity_map[identifier]
            return {
                'title': entity_info.get('title', ''),
                'type': entity_info.get('type', '')
            }
        return {'title': '', 'type': ''}
    
    def export_relations(self, relations_by_file: Dict[str, List[Dict[str, Any]]]):
        """
        å¯¼å‡ºå…³ç³»æ•°æ®åˆ°Excelï¼Œæ¯ä¸ªå…³ç³»æ–‡ä»¶ä¸€ä¸ªsheet
        
        Args:
            relations_by_file: æŒ‰æ–‡ä»¶ååˆ†ç»„çš„å…³ç³»å­—å…¸
        """
        output_file = self.output_dir / f"{self.subject_name}_å…³ç³»æ•°æ®.xlsx"
        log_file = self.output_dir / f"{self.subject_name}_ç¼ºå¤±èŠ‚ç‚¹æ—¥å¿—.txt"
        
        print(f"\nğŸ“ å¯¼å‡ºå…³ç³»æ•°æ®åˆ°: {output_file}")
        
        missing_source_all = set()
        missing_target_all = set()
        missing_details = []  # è¯¦ç»†è®°å½•ç¼ºå¤±ä¿¡æ¯
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            for file_name, relations in sorted(relations_by_file.items()):
                print(f"  å¤„ç† {file_name}: {len(relations)} ä¸ªå…³ç³»")
                
                rows = []
                missing_source = set()
                missing_target = set()
                
                for idx, rel in enumerate(relations, 1):
                    source_id = rel.get('source', '')
                    target_id = rel.get('target', '')
                    relation_name = rel.get('relationName', rel.get('label', ''))
                    
                    # è·å–æºèŠ‚ç‚¹ä¿¡æ¯
                    source_info = self.get_entity_info(source_id)
                    if not source_info['title']:
                        missing_source.add(source_id)
                        missing_source_all.add(source_id)
                        missing_details.append({
                            'æ–‡ä»¶': file_name,
                            'è¡Œå·': idx,
                            'èŠ‚ç‚¹ä½ç½®': 'å¤´èŠ‚ç‚¹',
                            'èŠ‚ç‚¹ID': source_id,
                            'å…³ç³»åç§°': relation_name,
                            'å°¾èŠ‚ç‚¹ID': target_id
                        })
                    
                    # è·å–ç›®æ ‡èŠ‚ç‚¹ä¿¡æ¯
                    target_info = self.get_entity_info(target_id)
                    if not target_info['title']:
                        missing_target.add(target_id)
                        missing_target_all.add(target_id)
                        missing_details.append({
                            'æ–‡ä»¶': file_name,
                            'è¡Œå·': idx,
                            'èŠ‚ç‚¹ä½ç½®': 'å°¾èŠ‚ç‚¹',
                            'èŠ‚ç‚¹ID': target_id,
                            'å…³ç³»åç§°': relation_name,
                            'å¤´èŠ‚ç‚¹ID': source_id
                        })
                    
                    row = {
                        'å¤´èŠ‚ç‚¹åç§°': self.clean_cell_value(source_info['title']),
                        'å¤´èŠ‚ç‚¹ç±»å‹': self.clean_cell_value(source_info['type']),
                        'å¤´èŠ‚ç‚¹ID': self.clean_cell_value(source_id),
                        'å°¾èŠ‚ç‚¹åç§°': self.clean_cell_value(target_info['title']),
                        'å°¾èŠ‚ç‚¹ç±»å‹': self.clean_cell_value(target_info['type']),
                        'å°¾èŠ‚ç‚¹ID': self.clean_cell_value(target_id),
                        'å…³ç³»åç§°': self.clean_cell_value(relation_name),
                    }
                    
                    # æ·»åŠ å…¶ä»–å­—æ®µ
                    for key, value in rel.items():
                        if key not in ['source', 'target', 'relationName', 'label']:
                            if isinstance(value, (list, dict)):
                                json_str = json.dumps(value, ensure_ascii=False)
                                row[key] = self.clean_cell_value(json_str)
                            else:
                                row[key] = self.clean_cell_value(value)
                    
                    rows.append(row)
                
                # åˆ›å»ºDataFrame
                df = pd.DataFrame(rows)
                
                # ç¡®ä¿åˆ—é¡ºåº
                base_cols = ['å¤´èŠ‚ç‚¹åç§°', 'å¤´èŠ‚ç‚¹ç±»å‹', 'å¤´èŠ‚ç‚¹ID', 
                             'å°¾èŠ‚ç‚¹åç§°', 'å°¾èŠ‚ç‚¹ç±»å‹', 'å°¾èŠ‚ç‚¹ID', 'å…³ç³»åç§°']
                other_cols = [c for c in df.columns if c not in base_cols]
                df = df[base_cols + other_cols]
                
                # å†™å…¥sheetï¼ˆsheetåç§°é™åˆ¶31å­—ç¬¦ï¼Œæ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼‰
                sheet_name = file_name[:31] if len(file_name) <= 31 else file_name[:28] + '...'
                # Excel sheetåç§°ä¸èƒ½åŒ…å«æŸäº›å­—ç¬¦
                sheet_name = sheet_name.replace('/', '_').replace('\\', '_').replace('?', '_')
                sheet_name = sheet_name.replace('*', '_').replace('[', '_').replace(']', '_')
                sheet_name = sheet_name.replace(':', '_')
                
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        # å†™å…¥è¯¦ç»†æ—¥å¿—
        self.write_missing_log(log_file, missing_details, missing_source_all, missing_target_all)
        
        print(f"âœ… å…³ç³»æ•°æ®å¯¼å‡ºå®Œæˆ: {output_file}")
        
        if missing_source_all:
            print(f"âš ï¸  è­¦å‘Š: {len(missing_source_all)} ä¸ªå¤´èŠ‚ç‚¹æœªæ‰¾åˆ°å®ä½“ä¿¡æ¯")
        if missing_target_all:
            print(f"âš ï¸  è­¦å‘Š: {len(missing_target_all)} ä¸ªå°¾èŠ‚ç‚¹æœªæ‰¾åˆ°å®ä½“ä¿¡æ¯")
        
        if missing_details:
            print(f"ğŸ“‹ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
    
    def write_missing_log(self, log_file: Path, missing_details: List[Dict[str, Any]], 
                         missing_source_all: set, missing_target_all: set):
        """
        å†™å…¥ç¼ºå¤±èŠ‚ç‚¹çš„è¯¦ç»†æ—¥å¿—
        
        Args:
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            missing_details: ç¼ºå¤±èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯åˆ—è¡¨
            missing_source_all: æ‰€æœ‰ç¼ºå¤±çš„å¤´èŠ‚ç‚¹IDé›†åˆ
            missing_target_all: æ‰€æœ‰ç¼ºå¤±çš„å°¾èŠ‚ç‚¹IDé›†åˆ
        """
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write(f"ç¼ºå¤±èŠ‚ç‚¹ä¿¡æ¯æ—¥å¿— - {self.subject_name}\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*80 + "\n\n")
            
            # ç»Ÿè®¡æ‘˜è¦
            f.write("ã€ç»Ÿè®¡æ‘˜è¦ã€‘\n")
            f.write(f"  ç¼ºå¤±å¤´èŠ‚ç‚¹æ€»æ•°: {len(missing_source_all)}\n")
            f.write(f"  ç¼ºå¤±å°¾èŠ‚ç‚¹æ€»æ•°: {len(missing_target_all)}\n")
            f.write(f"  æ¶‰åŠçš„å…³ç³»æ–‡ä»¶æ•°: {len(set(d['æ–‡ä»¶'] for d in missing_details))}\n")
            f.write(f"  æ¶‰åŠçš„å…³ç³»æ€»æ•°: {len(missing_details)}\n")
            f.write("\n")
            
            # æŒ‰æ–‡ä»¶åˆ†ç»„æ˜¾ç¤º
            f.write("="*80 + "\n")
            f.write("ã€æŒ‰å…³ç³»æ–‡ä»¶åˆ†ç»„ã€‘\n")
            f.write("="*80 + "\n\n")
            
            files_summary = {}
            for detail in missing_details:
                file_name = detail['æ–‡ä»¶']
                if file_name not in files_summary:
                    files_summary[file_name] = {
                        'å¤´èŠ‚ç‚¹': [],
                        'å°¾èŠ‚ç‚¹': []
                    }
                
                if detail['èŠ‚ç‚¹ä½ç½®'] == 'å¤´èŠ‚ç‚¹':
                    files_summary[file_name]['å¤´èŠ‚ç‚¹'].append(detail)
                else:
                    files_summary[file_name]['å°¾èŠ‚ç‚¹'].append(detail)
            
            for file_name in sorted(files_summary.keys()):
                summary = files_summary[file_name]
                f.write(f"\næ–‡ä»¶: {file_name}.json\n")
                f.write("-" * 80 + "\n")
                
                # å¤´èŠ‚ç‚¹ç¼ºå¤±
                if summary['å¤´èŠ‚ç‚¹']:
                    f.write(f"\n  ç¼ºå¤±å¤´èŠ‚ç‚¹ ({len(summary['å¤´èŠ‚ç‚¹'])} ä¸ª):\n")
                    for detail in summary['å¤´èŠ‚ç‚¹']:
                        f.write(f"    è¡Œå· {detail['è¡Œå·']:4d} | ")
                        f.write(f"èŠ‚ç‚¹ä½ç½®: {detail['èŠ‚ç‚¹ä½ç½®']:6s} | ")
                        f.write(f"èŠ‚ç‚¹ID: {detail['èŠ‚ç‚¹ID']}\n")
                        f.write(f"            | å…³ç³»åç§°: {detail['å…³ç³»åç§°']}\n")
                        f.write(f"            | å°¾èŠ‚ç‚¹ID: {detail['å°¾èŠ‚ç‚¹ID']}\n")
                        f.write("\n")
                
                # å°¾èŠ‚ç‚¹ç¼ºå¤±
                if summary['å°¾èŠ‚ç‚¹']:
                    f.write(f"\n  ç¼ºå¤±å°¾èŠ‚ç‚¹ ({len(summary['å°¾èŠ‚ç‚¹'])} ä¸ª):\n")
                    for detail in summary['å°¾èŠ‚ç‚¹']:
                        f.write(f"    è¡Œå· {detail['è¡Œå·']:4d} | ")
                        f.write(f"èŠ‚ç‚¹ä½ç½®: {detail['èŠ‚ç‚¹ä½ç½®']:6s} | ")
                        f.write(f"èŠ‚ç‚¹ID: {detail['èŠ‚ç‚¹ID']}\n")
                        f.write(f"            | å…³ç³»åç§°: {detail['å…³ç³»åç§°']}\n")
                        f.write(f"            | å¤´èŠ‚ç‚¹ID: {detail['å¤´èŠ‚ç‚¹ID']}\n")
                        f.write("\n")
            
            # æŒ‰èŠ‚ç‚¹IDæ±‡æ€»
            f.write("\n" + "="*80 + "\n")
            f.write("ã€æŒ‰ç¼ºå¤±èŠ‚ç‚¹IDæ±‡æ€»ã€‘\n")
            f.write("="*80 + "\n\n")
            
            # å¤´èŠ‚ç‚¹æ±‡æ€»
            if missing_source_all:
                f.write("ç¼ºå¤±çš„å¤´èŠ‚ç‚¹IDåˆ—è¡¨:\n")
                for node_id in sorted(missing_source_all):
                    # æ‰¾å‡ºæ‰€æœ‰ä½¿ç”¨è¿™ä¸ªå¤´èŠ‚ç‚¹çš„å…³ç³»
                    related_rels = [d for d in missing_details 
                                   if d['èŠ‚ç‚¹ä½ç½®'] == 'å¤´èŠ‚ç‚¹' and d['èŠ‚ç‚¹ID'] == node_id]
                    f.write(f"  {node_id}\n")
                    f.write(f"    å‡ºç°åœ¨ {len(related_rels)} ä¸ªå…³ç³»ä¸­:\n")
                    for rel in related_rels[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        f.write(f"      - {rel['æ–‡ä»¶']}.json (è¡Œå· {rel['è¡Œå·']}, å…³ç³»: {rel['å…³ç³»åç§°']})\n")
                    if len(related_rels) > 5:
                        f.write(f"      ... è¿˜æœ‰ {len(related_rels) - 5} ä¸ªå…³ç³»\n")
                    f.write("\n")
            
            # å°¾èŠ‚ç‚¹æ±‡æ€»
            if missing_target_all:
                f.write("\nç¼ºå¤±çš„å°¾èŠ‚ç‚¹IDåˆ—è¡¨:\n")
                for node_id in sorted(missing_target_all):
                    # æ‰¾å‡ºæ‰€æœ‰ä½¿ç”¨è¿™ä¸ªå°¾èŠ‚ç‚¹çš„å…³ç³»
                    related_rels = [d for d in missing_details 
                                   if d['èŠ‚ç‚¹ä½ç½®'] == 'å°¾èŠ‚ç‚¹' and d['èŠ‚ç‚¹ID'] == node_id]
                    f.write(f"  {node_id}\n")
                    f.write(f"    å‡ºç°åœ¨ {len(related_rels)} ä¸ªå…³ç³»ä¸­:\n")
                    for rel in related_rels[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        f.write(f"      - {rel['æ–‡ä»¶']}.json (è¡Œå· {rel['è¡Œå·']}, å…³ç³»: {rel['å…³ç³»åç§°']})\n")
                    if len(related_rels) > 5:
                        f.write(f"      ... è¿˜æœ‰ {len(related_rels) - 5} ä¸ªå…³ç³»\n")
                    f.write("\n")
            
            f.write("\n" + "="*80 + "\n")
            f.write("ã€æ’æŸ¥å»ºè®®ã€‘\n")
            f.write("="*80 + "\n")
            f.write("1. æ£€æŸ¥entitiesç›®å½•ä¸­æ˜¯å¦å­˜åœ¨å¯¹åº”çš„å®ä½“æ–‡ä»¶\n")
            f.write("2. æ£€æŸ¥å®ä½“æ–‡ä»¶ä¸­çš„identifierå­—æ®µæ˜¯å¦ä¸å…³ç³»æ–‡ä»¶ä¸­çš„source/targetå®Œå…¨åŒ¹é…\n")
            f.write("3. æ³¨æ„identifierçš„å¤§å°å†™ã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰ç»†èŠ‚\n")
            f.write("4. æ£€æŸ¥æ˜¯å¦æœ‰å®ä½“æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ˆJSONè§£æå¤±è´¥ï¼‰\n")
            f.write("5. æ£€æŸ¥æ˜¯å¦æœ‰å®ä½“æ–‡ä»¶è¢«é—æ¼æœªåŠ è½½\n")
            f.write("="*80 + "\n")
    
    def export(self):
        """æ‰§è¡Œå®Œæ•´å¯¼å‡ºæµç¨‹"""
        print("="*60)
        print(f"ğŸ“Š JSONæ•°æ®å¯¼å‡ºå·¥å…·")
        print(f"   æ•°æ®ç›®å½•: {self.data_dir}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        print("="*60)
        
        # 1. åŠ è½½å®ä½“
        entities_by_type = self.load_entities()
        
        if not entities_by_type:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å®ä½“æ•°æ®ï¼Œæ— æ³•å¯¼å‡º")
            return
        
        # 2. å¯¼å‡ºå®ä½“æ•°æ®
        self.export_entities(entities_by_type)
        
        # 3. åŠ è½½å…³ç³»
        relations_by_file = self.load_relations()
        
        if not relations_by_file:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å…³ç³»æ•°æ®")
        else:
            # 4. å¯¼å‡ºå…³ç³»æ•°æ®
            self.export_relations(relations_by_file)
        
        print("\n" + "="*60)
        print("âœ… å¯¼å‡ºå®Œæˆï¼")
        print("="*60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='JSONæ•°æ®å¯¼å‡ºä¸ºExcelå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  # å¯¼å‡ºå•ä¸ªå­¦ç§‘
  python3 json2csv.py "å›¾è°±æ•°æ®/é«˜ä¸­æ•°å­¦-with-books"
  
  # æŒ‡å®šè¾“å‡ºç›®å½•
  python3 json2csv.py "å›¾è°±æ•°æ®/é«˜ä¸­æ•°å­¦-with-books" -o "å¯¼å‡ºæ•°æ®"
  
  # æ‰¹é‡å¯¼å‡ºæ‰€æœ‰å­¦ç§‘ï¼ˆéœ€è¦æ‰‹åŠ¨æŒ‡å®šï¼‰
  for dir in å›¾è°±æ•°æ®/*/; do python3 json2csv.py "$dir"; done
        '''
    )
    parser.add_argument('data_dir', type=str, nargs='?', help='æ•°æ®ç›®å½•è·¯å¾„ï¼ˆåŒ…å«entitieså’Œrelationså­ç›®å½•ï¼‰')
    parser.add_argument('-o', '--output', type=str, default=None, help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ï¼šæ•°æ®ç›®å½•åŒçº§/å¯¼å‡ºæ•°æ®ï¼‰')
    parser.add_argument('--all', action='store_true', help='æ‰¹é‡å¯¼å‡ºæ‰€æœ‰å­¦ç§‘ï¼ˆéœ€è¦æŒ‡å®šæ•°æ®æ ¹ç›®å½•ï¼‰')
    
    args = parser.parse_args()
    
    if args.all:
        # æ‰¹é‡å¯¼å‡ºæ¨¡å¼
        if not args.data_dir:
            print("âŒ é”™è¯¯: æ‰¹é‡å¯¼å‡ºæ¨¡å¼éœ€è¦æŒ‡å®šæ•°æ®æ ¹ç›®å½•")
            print("   ä¾‹å¦‚: python3 json2csv.py å›¾è°±æ•°æ® --all")
            return
        
        data_root = Path(args.data_dir)
        if not data_root.exists():
            print(f"âŒ é”™è¯¯: æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {data_root}")
            return
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«entitieså­ç›®å½•çš„ç›®å½•
        subject_dirs = [d for d in data_root.iterdir() 
                        if d.is_dir() and (d / 'entities').exists()]
        
        if not subject_dirs:
            print(f"âŒ é”™è¯¯: åœ¨ {data_root} ä¸­æœªæ‰¾åˆ°åŒ…å«entitieså­ç›®å½•çš„å­¦ç§‘ç›®å½•")
            return
        
        print(f"ğŸ“š æ‰¾åˆ° {len(subject_dirs)} ä¸ªå­¦ç§‘ç›®å½•ï¼Œå¼€å§‹æ‰¹é‡å¯¼å‡º...\n")
        
        for i, subject_dir in enumerate(sorted(subject_dirs), 1):
            print(f"\n{'='*60}")
            print(f"[{i}/{len(subject_dirs)}] å¤„ç†: {subject_dir.name}")
            print('='*60)
            
            try:
                exporter = Json2CsvExporter(str(subject_dir), args.output)
                exporter.export()
            except Exception as e:
                print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\n{'='*60}")
        print(f"âœ… æ‰¹é‡å¯¼å‡ºå®Œæˆï¼å…±å¤„ç† {len(subject_dirs)} ä¸ªå­¦ç§‘")
        print('='*60)
    
    else:
        # å•ä¸ªå¯¼å‡ºæ¨¡å¼
        if not args.data_dir:
            parser.print_help()
            return
        
        data_dir = Path(args.data_dir)
        if not data_dir.exists():
            print(f"âŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return
        
        # æ‰§è¡Œå¯¼å‡º
        exporter = Json2CsvExporter(str(data_dir), args.output)
        exporter.export()


if __name__ == '__main__':
    main()
